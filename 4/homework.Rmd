---
title: "Homework"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Reconstruction with PCA 

## Approximation of the ozone data

Air pollution is currently one of the most serious public health worries worldwide. 
The data is contained in the file ozone.txt.

### 1 - Perform the PCA on the ozone data

```{r}
library(FactoMineR)
library(reshape2)
library(ggplot2)
library(png)
library(EBImage)
library(ripa)
Ozone <-  read.table("ozone.txt",header = TRUE, sep = " ", row.names = 1)
res.pca <- PCA(Ozone , quanti.sup =1,quali.sup = 12:13,graph=FALSE,ncp=10)

plot(res.pca, choix = "var", axes = c(1, 2),label = "quanti.sup")
plot(res.pca, choix = "ind", habillage = ncol(Ozone), cex = 0.8,label = "quali")
```


##### Interpretation of the observation plot

```{r}
plot(res.pca, choix = "var", axes = c(1, 2),label = "var",col.var="brown")
```

##### Correlation between variables

We can separate our variables into 3 high within-correlation sets:

 * T9,T12,T15
 * Ne9, Ne12, Ne15
 * Wx9, Wx12, Wx15
 
##### Percentage of variability

The end points of the projected vectors are very close to the circle. It means the norm of the vectors hasn't been affected that much by the projection. Overall, the PCA preserved the variance of the Ozone data.


```{r}
res.pca$eig[1:2,]
```

Dim 1 stands for 54.94% of the variance distribution.

Dim 2 stands for 18,45% of the variance distribution.

Overall, __73.39% of the variance distribution is preserved__, which is satisfying.


##### Explain the interest of performing this PCA before a regression

PCA enables us to graphically __approximate the variables correlation__. Since regression is only meaningful for correlated variables, we can perform PCA before performing regression.

Besides we can evaluate beforehand what the general tendendy of the regression will be. For instance, maxO3 is positively correlated with T15, but negatively correlated with Ne15.



### 2 - Reconstruct the data

With the PCA outputs, one could reconstruct the data. First, reconstruct the data with one dimension. You should be aware that with the results of PCA, you could reconstruct the centered and scaled data, so that you may need to _add the means_ and _multiply by the standard deviations_ to get the approximation of the original matrix.

<br />

Here we manually reconstruct the 10 features by multiplying the coordinates of our variables in the new base, by the vectors of the new base - ie. their coordinates in their previous base.

<br />

```{r}
coord.var = as.matrix(res.pca$var$coord)[, 1, drop = F]
coord.ind = as.matrix(res.pca$ind$coord)[, 1, drop = F]
Ozone_r = coord.ind %*% t(sweep(coord.var, 2, sqrt(res.pca$eig[1,1]), FUN = "/"))
Ozone_r = sweep(Ozone_r, 2, res.pca$call$ecart.type, FUN = "*")
Ozone_r = sweep(Ozone_r, 2, res.pca$call$centre, FUN = "+")
Ozone_r= data.frame(Ozone_r)

plot(Ozone[,"maxO3y"])
plot(Ozone_r[,"maxO3y"])
```

### 3 - Plotting the maxO3y variable

Calling Xˆ the reconstructed matrix, observe the difference between X and Xˆ by plotting the variable maxO3y for the two matrices in function of the observations. Comment.

```{r}
Ozone_m <- data.frame(X=1:nrow(Ozone), max03 =Ozone[,"maxO3y"], max03_r = Ozone_r[,"maxO3y"])
Ozone_m <- melt(Ozone_m, id.vars = "X")
ggplot(Ozone_m, aes(x = X, y = value, color = variable)) +theme_bw() +geom_line()
```

##### Comment

The variance of the maxO3 variable has mostly been preserved. The result even after projection on a 1-dimensionnal space, is already close to the final data ! That is because max03y has a important composant according to the first PCA component. 

<br/>

We can then observe ```maxO3y = f(T9)``` __after projection__...

```{r}
ggplot(Ozone_r, aes(x = T9, y = maxO3y))+geom_line()
```

The linear relation obtained here is not surprising. (We projected on a one-dimensionnal space).

Below is the original relation between those two variables.

```{r}
ggplot(Ozone, aes(x = T9, y = maxO3y))+geom_line()+geom_smooth()
```

### 4 - Function to reconstruct the data with d dimensions
<br/>
We write a reconstruct function by hand.
<br/>

```{r}
reconstruct <- function (res, ncp) {
  ncp <- min(ncp, ncol(res$ind$coord))
  coord.var = as.matrix(res$var$coord)[, 1:ncp, drop = F]
  coord.ind = as.matrix(res$ind$coord)[, 1:ncp, drop = F]
  hatX = coord.ind %*% t(sweep(coord.var, 2, sqrt(res$eig[1:ncp,1]), FUN = "/"))
  hatX = sweep(hatX, 2, res$call$ecart.type, FUN = "*")
  hatX = sweep(hatX, 2, res$call$centre, FUN = "+")
  hatX = data.frame(hatX)
  return(hatX)
}
```

We will represent __maxO3y__, for the *original* and the *reconstructed* data (observed and estimated).

```{r}
represent <- function(Ozone_r){
  Ozone_m <- data.frame(X=1:nrow(Ozone), max03y = Ozone[,"maxO3y"], max03y_r = Ozone_r[,"maxO3y"])
  Ozone_m <- melt(Ozone_m, id.vars = "X")
  ggplot(Ozone_m, aes(x = X, y = value, color = variable)) +theme_bw() +geom_line()
}  
```

##### 2 dimensions

```{r}
represent(reconstruct(res.pca,ncp=4))
```

##### 3 dimensions

We can also use the reconst function provided in the FactoMineR package.

```{r}
represent(reconst(res.pca,ncp=10))
```

##### 5 dimensions

Already very close to the original data.

```{r}
represent(reconst(res.pca,ncp=5))
```

##### 10 dimensions

Perfectly identical to the original data.

```{r}
Ozone_tmp <- reconst(res.pca,ncp=10) 

# The data is already renormalized thanks to reconst
# Otherwise, we could have done :
# Ozone_tmp <- sweep(data.frame(Ozone_tmp),2,sdO,FUN="*")
# Ozone_tmp <- sweep(Ozone_tmp,2,moyO,FUN="+")

represent(Ozone_tmp)
```

##### Note

If we wanted to have the coordinate of max03, along the PCA components

```{r}
res.pca$quanti.sup$coord[,1]
```


## Reconstruct of an image

Import the data missing.jpg or breton.png and reconstruct the image with 1 to 100 dimensions. There are different packages dedicated to images. With the following lines of code, you could read an image, reprensent it and then transform it in a grey scale. (Be careful that you may need to execute the code in the R console and not by knitting).

```{r}
img <- readImage("missing.jpg") 
display(img, method = "raster")

r <- imagematrix(img, type = "grey") 
display(r, method = "raster")
```

Using the grey image, reconstruct the image with 1 to 100 dimensions (with PCA and reconst function of FactoMineR). You should use the packages “jpeg” and “png” to export the image with functions

Let's display for these numbers of PCA components: 10,40,70,100

```{r}
img.pca = PCA(r, graph=FALSE,ncp = 100) 
# 100 is the max number of principal components computed
# reconstr(1:10)[2,]==reconstr(1)[2,] 

for (i in seq(10,100,30)){
  display(reconst(img.pca,ncp=i),method = "raster")
}
```

The folder reconstruct will hold all the 100 images.

```{r}
dir.create("reconstruct")
for (i in seq(1,100,1)){
  png(filename=paste("reconstruct/",toString(i),".png",sep=""))
  display(reconst(img.pca,ncp=i),method = "raster")
  dev.off()
}
```

##### Comment.

We already get the overall shape of the picture using about __10 components from PCA__.

We can clearly read the picture using __40 components__.

Of course, the more elements, the clearer the picture, and we need approximately __100 components__ to distinguish the word "FOUNDATION" from the poster.


